{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: <br>\n",
    "[drivendata.org link](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/data/) [login required]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 2: EDA (Exploratory Data Analysis)\n",
    "**Author:<br>\n",
    "Tashi T. Gurung**<br>\n",
    "**hseb.tashi@gmail.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the project:\n",
    "The **objective** of this project is to **predict the failure of water points** spread accross Tanzania before they occur.\n",
    "\n",
    "50% of Tanzania's population do not have access to safe water. Among other sources, Tanzanians depend on water points mostly pumps (~60K) spread across Tanzania. Compared to other infrastructure projects, water point projects consist of a huge number of inspection points that are geographically spread out. Gathering data on the condition of these pumps has been a challenge. From working with local agencies, to implementing mobile based crowd sourcing projects, none have produced satisfactory results.\n",
    "\n",
    "The lack of quality data creates a number of problem for a stakeholder like the Tanzanian Government, specifically the Ministry of Water. Consequences include not only higher maintainence costs, but also all the problems and nuanced issues faced by communities when their access to water is compromised or threatened.\n",
    "\n",
    "While better data collection infrastructure should be built overtime, this project (with its model(s), various analysis, and insights) will be key for efficient resource allocation to maximize the number of people and communities with access to water.\n",
    "In the long run, it will assist stake holders in and project planning, and even local, regional and national level policy formation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Filter out FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/processed/modified_data.csv\", parse_dates=['date_recorded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types to object\n",
    "columns_to_convert_to_object = ['district_code', 'region_code']\n",
    "df[columns_to_convert_to_object] = df[columns_to_convert_to_object].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.to_list()\n",
    "categorical_columns.remove('status_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funder                    1896\n",
      "installer                 2145\n",
      "wpt_name                 37399\n",
      "basin                        9\n",
      "subvillage               19287\n",
      "region                      21\n",
      "region_code                 27\n",
      "district_code               19\n",
      "lga                        125\n",
      "ward                      2092\n",
      "public_meeting               3\n",
      "recorded_by                  1\n",
      "scheme_management           11\n",
      "scheme_name               2696\n",
      "permit                       3\n",
      "extraction_type             18\n",
      "extraction_type_group       13\n",
      "extraction_type_class        7\n",
      "management                  12\n",
      "management_group             5\n",
      "payment                      7\n",
      "payment_type                 7\n",
      "water_quality                8\n",
      "quality_group                6\n",
      "quantity                     5\n",
      "quantity_group               5\n",
      "source                      10\n",
      "source_type                  7\n",
      "source_class                 3\n",
      "waterpoint_type              7\n",
      "waterpoint_type_group        6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate cardinality (number of unique values) for each categorical column\n",
    "cardinality = df[categorical_columns].nunique()\n",
    "\n",
    "# Display the cardinality of each categorical column\n",
    "print(cardinality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status_group'] = df['status_group'].map({\n",
    "    'functional': 2,\n",
    "    'non functional': 0,\n",
    "    'functional needs repair': 1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wpt_name_encoded  status_group\n",
      "0          1.496774             2\n",
      "1          1.130120             2\n",
      "2          1.288769             2\n",
      "3          1.008064             0\n",
      "4          1.064645             2\n"
     ]
    }
   ],
   "source": [
    "# Import the required library\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Initialize the target encoder\n",
    "encoder = TargetEncoder()\n",
    "\n",
    "# Encode the \"wpt_name\" column using the target encoder\n",
    "df['wpt_name_encoded'] = encoder.fit_transform(df['wpt_name'], df['status_group'])\n",
    "\n",
    "# Drop the original \"wpt_name\" column\n",
    "df.drop('wpt_name', axis=1, inplace=True)\n",
    "\n",
    "# Print the first few rows to check the result\n",
    "print(df[['wpt_name_encoded', 'status_group']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets follow the same for the remaining high cardinality features\n",
    "\n",
    "# Encode the \"subvillage\" column using the target encoder\n",
    "df['subvillage_encoded'] = encoder.fit_transform(df['subvillage'], df['status_group'])\n",
    "\n",
    "# Encode the \"ward\" column using the target encoder\n",
    "df['ward_encoded'] = encoder.fit_transform(df['ward'], df['status_group'])\n",
    "\n",
    "# Encode the \"scheme_name\" column using the target encoder\n",
    "df['scheme_name_encoded'] = encoder.fit_transform(df['scheme_name'], df['status_group'])\n",
    "\n",
    "# Drop the original categorical columns\n",
    "df.drop(['subvillage', 'ward', 'scheme_name'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funder: object, Cardinality: 1896\n",
      "installer: object, Cardinality: 2145\n",
      "basin: object, Cardinality: 9\n",
      "region: object, Cardinality: 21\n",
      "region_code: object, Cardinality: 27\n",
      "district_code: object, Cardinality: 19\n",
      "lga: object, Cardinality: 125\n",
      "public_meeting: object, Cardinality: 3\n",
      "recorded_by: object, Cardinality: 1\n",
      "scheme_management: object, Cardinality: 11\n",
      "permit: object, Cardinality: 3\n",
      "extraction_type: object, Cardinality: 18\n",
      "extraction_type_group: object, Cardinality: 13\n",
      "extraction_type_class: object, Cardinality: 7\n",
      "management: object, Cardinality: 12\n",
      "management_group: object, Cardinality: 5\n",
      "payment: object, Cardinality: 7\n",
      "payment_type: object, Cardinality: 7\n",
      "water_quality: object, Cardinality: 8\n",
      "quality_group: object, Cardinality: 6\n",
      "quantity: object, Cardinality: 5\n",
      "quantity_group: object, Cardinality: 5\n",
      "source: object, Cardinality: 10\n",
      "source_type: object, Cardinality: 7\n",
      "source_class: object, Cardinality: 3\n",
      "waterpoint_type: object, Cardinality: 7\n",
      "waterpoint_type_group: object, Cardinality: 6\n"
     ]
    }
   ],
   "source": [
    "# Calculate cardinality (number of unique values) for each categorical column\n",
    "\n",
    "new_categorical_columns = df.select_dtypes(include=['object']).columns.to_list()\n",
    "cardinality = df[new_categorical_columns].nunique()\n",
    "\n",
    "# Display data type and cardinality side by side\n",
    "for column in new_categorical_columns:\n",
    "    print(f\"{column}: {df[column].dtype}, Cardinality: {cardinality[column]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** \n",
    "- we still have two features: funder, and installer with relatively high cardinality\n",
    "\n",
    "**Action:**\n",
    "- Lets look into thesee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.where to replace values\n",
    "df[\"funder\"] = np.where(df[\"funder\"] == \"Government Of Tanzania\", df[\"funder\"], \"other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumps_per_installer = df[\"installer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_installer(installer):\n",
    "    if pumps_per_installer[installer]  > 10_000:\n",
    "        return \"large\"\n",
    "    elif pumps_per_installer[installer]  > 1:\n",
    "        return \"mid\"\n",
    "    else:\n",
    "        return \"small\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the categorization function to the 'installer' column\n",
    "df['installer_category'] = df['installer'].apply(categorize_installer)\n",
    "df.drop(columns = ['installer'] , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'region',  # region_code already provides that information\n",
    "    'lga',  # need to look into it further\n",
    "    'recorded_by',  # all rows have the same value\n",
    "    'extraction_type_group',\n",
    "    'extraction_type_class',  # for both of these, extraction_type already provides the info\n",
    "    'payment_type',  # info provided by payment\n",
    "    'quality_group',  # info provided by quality\n",
    "    'source_type',  # info provided by source\n",
    "    'source_class',  # info provided by source\n",
    "    'waterpoint_type_group',  # info provided by waterpoint_type\n",
    "]\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns to one-hot encode\n",
    "categorical_columns_to_encode  = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Perform one-hot encoding for the specified columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns_to_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new feature called *age*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['year_recorded'] = df_encoded['date_recorded'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 'age' by subtracting 'construction_year' from 'year_recorded'\n",
    "df_encoded['age'] = df_encoded['year_recorded'] - df_encoded['construction_year']\n",
    "df_encoded.drop(columns = ['date_recorded', 'year_recorded'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_csv('../data/processed/preprocessed_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
