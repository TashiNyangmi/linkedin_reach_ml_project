{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 2_3: Preprocessing - Handling Categorical Features\n",
    "**Author:<br>\n",
    "Tashi T. Gurung**<br>\n",
    "**hseb.tashi@gmail.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the project:\n",
    "The **objective** of this project is to **predict the failure of water points** spread accross Tanzania before they occur.\n",
    "\n",
    "50% of Tanzania's population do not have access to safe water. Among other sources, Tanzanians depend on water points mostly pumps (~60K) spread across Tanzania. Compared to other infrastructure projects, water point projects consist of a huge number of inspection points that are geographically spread out. Gathering data on the condition of these pumps has been a challenge. From working with local agencies, to implementing mobile based crowd sourcing projects, none have produced satisfactory results.\n",
    "\n",
    "The lack of quality data creates a number of problem for a stakeholder like the Tanzanian Government, specifically the Ministry of Water. Consequences include not only higher maintainence costs, but also all the problems and nuanced issues faced by communities when their access to water is compromised or threatened.\n",
    "\n",
    "While better data collection infrastructure should be built overtime, this project (with its model(s), various analysis, and insights) will be key for efficient resource allocation to maximize the number of people and communities with access to water.\n",
    "In the long run, it will assist stake holders in and project planning, and even local, regional and national level policy formation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Filter out FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json file with desired data type information \n",
    "json_file_path = '../data/processed/data_types.json'\n",
    "\n",
    "# Read and load the JSON file into a dictionary\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    data_types_dict = json.load(json_file)\n",
    "\n",
    "data_types_dict['longitude'] = 'float64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>...</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Mnyusi B</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Nyamara</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh date_recorded   funder  gps_height installer  longitude  \\\n",
       "0      6000.0    2011-03-14    Roman        1390     Roman  34.938093   \n",
       "1         0.0    2013-03-06  Grumeti        1399   GRUMETI  34.698766   \n",
       "\n",
       "   latitude  wpt_name          basin subvillage  ... water_quality  \\\n",
       "0 -9.856322      none     Lake Nyasa   Mnyusi B  ...          soft   \n",
       "1 -2.147466  Zahanati  Lake Victoria    Nyamara  ...          soft   \n",
       "\n",
       "  quality_group      quantity quantity_group                source  \\\n",
       "0          good        enough         enough                spring   \n",
       "1          good  insufficient   insufficient  rainwater harvesting   \n",
       "\n",
       "            source_type source_class     waterpoint_type  \\\n",
       "0                spring  groundwater  communal standpipe   \n",
       "1  rainwater harvesting      surface  communal standpipe   \n",
       "\n",
       "  waterpoint_type_group status_group  \n",
       "0    communal standpipe   functional  \n",
       "1    communal standpipe   functional  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/preprocessed_data.csv', dtype=data_types_dict)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types to object\n",
    "columns_to_convert_to_object = ['district_code', 'region_code']\n",
    "df[columns_to_convert_to_object] = df[columns_to_convert_to_object].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.to_list()\n",
    "categorical_columns.remove('status_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funder                    1896\n",
      "installer                 2145\n",
      "wpt_name                 37399\n",
      "basin                        9\n",
      "subvillage               19287\n",
      "region                      21\n",
      "region_code                 27\n",
      "district_code               19\n",
      "lga                        125\n",
      "ward                      2092\n",
      "public_meeting               3\n",
      "recorded_by                  1\n",
      "scheme_management           11\n",
      "scheme_name               2696\n",
      "permit                       3\n",
      "extraction_type             18\n",
      "extraction_type_group       13\n",
      "extraction_type_class        7\n",
      "management                  12\n",
      "management_group             5\n",
      "payment                      7\n",
      "payment_type                 7\n",
      "water_quality                8\n",
      "quality_group                6\n",
      "quantity                     5\n",
      "quantity_group               5\n",
      "source                      10\n",
      "source_type                  7\n",
      "source_class                 3\n",
      "waterpoint_type              7\n",
      "waterpoint_type_group        6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate cardinality (number of unique values) for each categorical column\n",
    "cardinality = df[categorical_columns].nunique()\n",
    "\n",
    "# Display the cardinality of each categorical column\n",
    "print(cardinality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status_group'] = df['status_group'].map({\n",
    "    'functional': 2,\n",
    "    'non functional': 0,\n",
    "    'functional needs repair': 1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wpt_name_encoded  status_group\n",
      "0          1.496774             2\n",
      "1          1.130120             2\n",
      "2          1.288769             2\n",
      "3          1.008064             0\n",
      "4          1.064645             2\n"
     ]
    }
   ],
   "source": [
    "# Import the required library\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Initialize the target encoder\n",
    "encoder = TargetEncoder()\n",
    "\n",
    "# Encode the \"wpt_name\" column using the target encoder\n",
    "df['wpt_name_encoded'] = encoder.fit_transform(df['wpt_name'], df['status_group'])\n",
    "\n",
    "# Drop the original \"wpt_name\" column\n",
    "df.drop('wpt_name', axis=1, inplace=True)\n",
    "\n",
    "# Print the first few rows to check the result\n",
    "print(df[['wpt_name_encoded', 'status_group']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets follow the same for the remaining high cardinality features\n",
    "\n",
    "# Encode the \"subvillage\" column using the target encoder\n",
    "df['subvillage_encoded'] = encoder.fit_transform(df['subvillage'], df['status_group'])\n",
    "\n",
    "# Encode the \"ward\" column using the target encoder\n",
    "df['ward_encoded'] = encoder.fit_transform(df['ward'], df['status_group'])\n",
    "\n",
    "# Encode the \"scheme_name\" column using the target encoder\n",
    "df['scheme_name_encoded'] = encoder.fit_transform(df['scheme_name'], df['status_group'])\n",
    "\n",
    "# Drop the original categorical columns\n",
    "df.drop(['subvillage', 'ward', 'scheme_name'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funder: object, Cardinality: 1896\n",
      "installer: object, Cardinality: 2145\n",
      "basin: object, Cardinality: 9\n",
      "region: object, Cardinality: 21\n",
      "region_code: object, Cardinality: 27\n",
      "district_code: object, Cardinality: 19\n",
      "lga: object, Cardinality: 125\n",
      "public_meeting: object, Cardinality: 3\n",
      "recorded_by: object, Cardinality: 1\n",
      "scheme_management: object, Cardinality: 11\n",
      "permit: object, Cardinality: 3\n",
      "extraction_type: object, Cardinality: 18\n",
      "extraction_type_group: object, Cardinality: 13\n",
      "extraction_type_class: object, Cardinality: 7\n",
      "management: object, Cardinality: 12\n",
      "management_group: object, Cardinality: 5\n",
      "payment: object, Cardinality: 7\n",
      "payment_type: object, Cardinality: 7\n",
      "water_quality: object, Cardinality: 8\n",
      "quality_group: object, Cardinality: 6\n",
      "quantity: object, Cardinality: 5\n",
      "quantity_group: object, Cardinality: 5\n",
      "source: object, Cardinality: 10\n",
      "source_type: object, Cardinality: 7\n",
      "source_class: object, Cardinality: 3\n",
      "waterpoint_type: object, Cardinality: 7\n",
      "waterpoint_type_group: object, Cardinality: 6\n"
     ]
    }
   ],
   "source": [
    "# Calculate cardinality (number of unique values) for each categorical column\n",
    "\n",
    "new_categorical_columns = df.select_dtypes(include=['object']).columns.to_list()\n",
    "cardinality = df[new_categorical_columns].nunique()\n",
    "\n",
    "# Display data type and cardinality side by side\n",
    "for column in new_categorical_columns:\n",
    "    print(f\"{column}: {df[column].dtype}, Cardinality: {cardinality[column]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** \n",
    "- we still have two features: funder, and installer with relatively high cardinality\n",
    "\n",
    "**Action:**\n",
    "- Lets look into thesee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.where to replace values\n",
    "df[\"funder\"] = np.where(df[\"funder\"] == \"Government Of Tanzania\", df[\"funder\"], \"other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumps_per_installer = df[\"installer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_installer(installer):\n",
    "    if pumps_per_installer[installer]  > 10_000:\n",
    "        return \"large\"\n",
    "    elif pumps_per_installer[installer]  > 1:\n",
    "        return \"mid\"\n",
    "    else:\n",
    "        return \"small\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the categorization function to the 'installer' column\n",
    "df['installer_category'] = df['installer'].apply(categorize_installer)\n",
    "df.drop(columns = ['installer'] , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'region',  # region_code already provides that information\n",
    "    'lga',  # need to look into it further\n",
    "    'recorded_by',  # all rows have the same value\n",
    "    'extraction_type_group',\n",
    "    'extraction_type_class',  # for both of these, extraction_type already provides the info\n",
    "    'payment_type',  # info provided by payment\n",
    "    'quality_group',  # info provided by quality\n",
    "    'source_type',  # info provided by source\n",
    "    'source_class',  # info provided by source\n",
    "    'waterpoint_type_group',  # info provided by waterpoint_type\n",
    "]\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns to one-hot encode\n",
    "categorical_columns_to_encode  = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Perform one-hot encoding for the specified columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns_to_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new feature called *age*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['year_recorded'] = df_encoded['date_recorded'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 'age' by subtracting 'construction_year' from 'year_recorded'\n",
    "df_encoded['age'] = df_encoded['year_recorded'] - df_encoded['construction_year']\n",
    "df_encoded.drop(columns = ['date_recorded', 'year_recorded'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_csv('../data/processed/preprocessed_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
