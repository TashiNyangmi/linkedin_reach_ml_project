{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: <br>\n",
    "[drivendata.org link](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/data/) [login required]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 3: Model Building and Evaluation\n",
    "**Author:<br>\n",
    "Tashi T. Gurung**<br>\n",
    "**hseb.tashi@gmail.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the project:\n",
    "The **objective** of this project is to **predict the failure of water points** spread accross Tanzania before they occur.\n",
    "\n",
    "50% of Tanzania's population do not have access to safe water. Among other sources, Tanzanians depend on water points mostly pumps (~60K) spread across Tanzania. Compared to other infrastructure projects, water point projects consist of a huge number of inspection points that are geographically spread out. Gathering data on the condition of these pumps has been a challenge. From working with local agencies, to implementing mobile based crowd sourcing projects, none have produced satisfactory results.\n",
    "\n",
    "The lack of quality data creates a number of problem for a stakeholder like the Tanzanian Government, specifically the Ministry of Water. Consequences include not only higher maintainence costs, but also all the problems and nuanced issues faced by communities when their access to water is compromised or threatened.\n",
    "\n",
    "While better data collection infrastructure should be built overtime, this project (with its model(s), various analysis, and insights) will be key for efficient resource allocation to maximize the number of people and communities with access to water.\n",
    "In the long run, it will assist stake holders in and project planning, and even local, regional and national level policy formation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed dataset\n",
    "df_encoded = pd.read_csv('../data/processed/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status_group\n",
       "2    0.543081\n",
       "0    0.384242\n",
       "1    0.072677\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded['status_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a dummy classifier that always returns 1 (funcitonal, functional needs repair), it would be accurate 54.3% of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8624579124579125\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4061   46  458]\n",
      " [ 187  172  504]\n",
      " [ 378   61 6013]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      4565\n",
      "           1       0.62      0.20      0.30       863\n",
      "           2       0.86      0.93      0.90      6452\n",
      "\n",
      "    accuracy                           0.86     11880\n",
      "   macro avg       0.79      0.67      0.69     11880\n",
      "weighted avg       0.85      0.86      0.85     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_encoded.drop('status_group', axis=1)\n",
    "y = df_encoded['status_group']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n",
    "\n",
    "# Standardize the features (mean = 0, variance = 1)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:<br>\n",
    "Predicted |   0    |    1    |    2    |<br>\n",
    "Actual <br>\n",
    "------- 0 |  4061  |   46    |   458   |<br>\n",
    "------- 1 |   187  |   172   |   504   |<br>\n",
    "------- 2 |   378  |    61   |   6013  |<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.85585017 0.85721801 0.85900673 0.86069024 0.86058502]\n",
      "Mean Accuracy: 0.8586700336700337\n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Define the cross-validation method\n",
    "cv_method = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the scoring metric you want to use, e.g., accuracy\n",
    "scoring_metric = make_scorer(accuracy_score)\n",
    "\n",
    "# Perform cross-validation and get the accuracy scores\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv_method, scoring=scoring_metric)\n",
    "\n",
    "# Print the accuracy scores for each fold\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "\n",
    "# Calculate the mean accuracy across all folds\n",
    "mean_accuracy = cv_scores.mean()\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- CV scores are consistent\n",
    "- Mean accuracy looks fair\n",
    "- No significant difference between the training accuracy (0.8624) and CV mean accuracy (0.8587)\n",
    "- Hence, overfitting less likely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters and their possible values to search:\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],  # Regularization penalty (L1 or L2)\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],  # Inverse of regularization strength\n",
    "    'solver': ['liblinear', 'lbfgs', 'saga'],  # Optimization algorithm\n",
    "    'max_iter': [100, 500, 1000],  # Maximum number of iterations for optimization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',  # Use the accuracy metric for evaluation\n",
    "    cv=cv_method,         # Use the same cross-validation method as before\n",
    "    verbose=1,            # Increase verbosity for progress updates\n",
    "    n_jobs=-1             # Use all available CPU cores\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9651515151515152\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4453   12  100]\n",
      " [  37  659  167]\n",
      " [  69   29 6354]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      4565\n",
      "           1       0.94      0.76      0.84       863\n",
      "           2       0.96      0.98      0.97      6452\n",
      "\n",
      "    accuracy                           0.97     11880\n",
      "   macro avg       0.96      0.91      0.93     11880\n",
      "weighted avg       0.96      0.97      0.96     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion)\n",
    "print(\"\\nClassification Report:\\n\", classification_report_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores (Random Forest): [0.96675084 0.96675084 0.96611953 0.96769781 0.9670665 ]\n",
      "Mean Accuracy (Random Forest): 0.9668771043771045\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the cross-validation method (Stratified K-Fold with 5 folds)\n",
    "cv_method = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the scoring metric (accuracy)\n",
    "scoring_metric = make_scorer(accuracy_score)\n",
    "\n",
    "# Perform cross-validation and get the accuracy scores\n",
    "cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=cv_method, scoring=scoring_metric)\n",
    "\n",
    "# Print the accuracy scores for each fold\n",
    "print(\"Cross-Validation Scores (Random Forest):\", cv_scores_rf)\n",
    "\n",
    "# Calculate the mean accuracy across all folds\n",
    "mean_accuracy_rf = cv_scores_rf.mean()\n",
    "print(\"Mean Accuracy (Random Forest):\", mean_accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- CV scores are consistent\n",
    "- Mean accuracy looks fair\n",
    "- No significant difference between the training accuracy (0.9651) and CV mean accuracy (0.9668)\n",
    "- Hence, overfitting less likely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid with hyperparameters to search\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create the Grid Search object\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, \n",
    "                               scoring='accuracy', cv=cv_method, n_jobs=-1)\n",
    "\n",
    "# Perform the Grid Search\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the search\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best Hyperparameters (Random Forest):\", best_params_rf)\n",
    "\n",
    "# Get the best cross-validated accuracy score\n",
    "best_score_rf = grid_search_rf.best_score_\n",
    "print(\"Best Cross-Validated Accuracy Score (Random Forest):\", best_score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9741582491582491\n",
      "Confusion Matrix:\n",
      " [[4442   18  105]\n",
      " [  23  762   78]\n",
      " [  68   15 6369]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      4565\n",
      "           1       0.96      0.88      0.92       863\n",
      "           2       0.97      0.99      0.98      6452\n",
      "\n",
      "    accuracy                           0.97     11880\n",
      "   macro avg       0.97      0.95      0.96     11880\n",
      "weighted avg       0.97      0.97      0.97     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to your training data\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on your test data\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBClassifier Results:\n",
      "Accuracy: 0.9792929292929293\n",
      "Confusion Matrix:\n",
      " [[4474   10   81]\n",
      " [  14  776   73]\n",
      " [  50   18 6384]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      4565\n",
      "           1       0.97      0.90      0.93       863\n",
      "           2       0.98      0.99      0.98      6452\n",
      "\n",
      "    accuracy                           0.98     11880\n",
      "   macro avg       0.98      0.96      0.97     11880\n",
      "weighted avg       0.98      0.98      0.98     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBClassifier\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate XGBClassifier\n",
    "print(\"\\nXGBClassifier Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, xgb_predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, xgb_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, xgb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores (XGBoost): [0.97843013 0.98211279 0.98095539 0.98200758 0.98190236]\n",
      "Mean Accuracy (XGBoost): 0.9810816498316498\n"
     ]
    }
   ],
   "source": [
    "# Create an XGBClassifier model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define the cross-validation method, e.g., Stratified K-Fold with 5 folds\n",
    "cv_method = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and get the accuracy scores\n",
    "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv_method, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy scores for each fold\n",
    "print(\"Cross-Validation Scores (XGBoost):\", cv_scores)\n",
    "\n",
    "# Calculate the mean accuracy across all folds\n",
    "mean_accuracy = cv_scores.mean()\n",
    "print(\"Mean Accuracy (XGBoost):\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- CV scores are consistent\n",
    "- Mean accuracy looks fair\n",
    "- No significant difference between the training accuracy (0.9792) and CV mean accuracy (0.9810)\n",
    "- Hence, overfitting less likely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (XG Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (80%) and temporary data (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Split the temporary data into validation (50%) and test (50%)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    " \n",
    "}\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "# Fit the tuner to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on validation data\n",
    "validation_accuracy = best_model.score(X_validation, y_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try a few more ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier Results:\n",
      "Accuracy: 0.9606902356902357\n",
      "Confusion Matrix:\n",
      " [[4411   22  132]\n",
      " [  66  700   97]\n",
      " [ 122   28 6302]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4565\n",
      "           1       0.93      0.81      0.87       863\n",
      "           2       0.96      0.98      0.97      6452\n",
      "\n",
      "    accuracy                           0.96     11880\n",
      "   macro avg       0.95      0.92      0.93     11880\n",
      "weighted avg       0.96      0.96      0.96     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "adaboost_model = AdaBoostClassifier(random_state=42)\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "adaboost_predictions = adaboost_model.predict(X_test)\n",
    "\n",
    "# Evaluate AdaBoostClassifier\n",
    "print(\"\\nAdaBoostClassifier Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, adaboost_predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, adaboost_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, adaboost_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation (Ada Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96346801 0.96473064 0.96144781 0.96641414 0.96355219]\n",
      "Mean Accuracy: 0.96\n",
      "Standard Deviation: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Create an AdaBoostClassifier instance \n",
    "adaboost_model = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation (e.g., with k=5)\n",
    "cross_val_scores = cross_val_score(adaboost_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cross_val_scores)\n",
    "\n",
    "# Calculate and print the mean accuracy and standard deviation\n",
    "mean_accuracy = cross_val_scores.mean()\n",
    "std_deviation = cross_val_scores.std()\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Standard Deviation: {std_deviation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (Ada Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AdaBoostClassifier\n",
    "ada_classifier = AdaBoostClassifier()\n",
    "\n",
    "# Define a dictionary of hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],       # Number of weak learners (decision trees)\n",
    "    'learning_rate': [0.1, 0.5, 1.0],    # Learning rate (step size at each iteration)\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the classifier and parameter grid\n",
    "grid_search = GridSearchCV(estimator=ada_classifier, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Perform the grid search with cross-validation\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a new AdaBoostClassifier with the best hyperparameters\n",
    "best_ada_classifier = AdaBoostClassifier(**best_params)\n",
    "\n",
    "# Fit the model on the entire training dataset\n",
    "best_ada_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "accuracy = best_ada_classifier.score(X_test, y_test)\n",
    "\n",
    "# Print the best hyperparameters and model accuracy\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
